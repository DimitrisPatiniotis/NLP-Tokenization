{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5e552989",
   "metadata": {},
   "source": [
    "<h1>NLP - Tokenization and Sentence Boundary Disambiguation</h1> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf849f97",
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with 'Python 3.10.4 64-bit (windows store)' requires ipykernel package.\n",
      "Run the following command to install 'ipykernel' into the Python environment. \n",
      "Command: 'C:/Users/gimi1/AppData/Local/Microsoft/WindowsApps/python3.10.exe -m pip install ipykernel -U --user --force-reinstall'"
     ]
    }
   ],
   "source": [
    "# Imports for tokenization task\n",
    "import os\n",
    "import re\n",
    "from collections import Counter\n",
    "import pandas as pd\n",
    "import itertools\n",
    "from nltk import word_tokenize\n",
    "from nltk.tokenize import wordpunct_tokenize\n",
    "from nltk.corpus import treebank\n",
    "import spacy\n",
    "from itertools import chain"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ad1da6c",
   "metadata": {},
   "source": [
    "<h2>Tokenization</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01bc3127",
   "metadata": {},
   "source": [
    "<h3>Function to extract tokenization metrics</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5e2521d",
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with 'Python 3.10.4 64-bit (windows store)' requires ipykernel package.\n",
      "Run the following command to install 'ipykernel' into the Python environment. \n",
      "Command: 'C:/Users/gimi1/AppData/Local/Microsoft/WindowsApps/python3.10.exe -m pip install ipykernel -U --user --force-reinstall'"
     ]
    }
   ],
   "source": [
    "# Get intercection between correct tokenization and others, the missing tokens as well as the wrong tokens contained in other tokenizations\n",
    "def get_tokenization_accuracy(correct_tokenization, other_tokenization):\n",
    "    unified_set = set(list(itertools.chain(correct_tokenization, other_tokenization)))\n",
    "    ot_set = set(other_tokenization)\n",
    "    cor_set = set(correct_tokenization)\n",
    "    intersection_len = ot_set.intersection(cor_set)\n",
    "    int_perc = round((len(intersection_len)*100 / len(unified_set)),2)\n",
    "    missing_tokens = list(cor_set.difference(ot_set))\n",
    "    wrong_tokens = list(ot_set.difference(cor_set))\n",
    "    return int_perc, missing_tokens, wrong_tokens\n",
    "\n",
    "# Get List of total number of types\n",
    "def get_tokenization_lens(tok_list):\n",
    "    return [len(i) for i in tok_list]\n",
    "\n",
    "# Get list of total number of types\n",
    "def get_type_lens(tok_list):\n",
    "    return [len(set(i)) for i in tok_list]\n",
    "\n",
    "# Get 30 most common tokens for each tokenizaiton\n",
    "def get_ind_common_tokens(tok_list):\n",
    "    return list(dict.fromkeys([item for items, c in Counter(tok_list).most_common() for item in [items] * c]))[:30]\n",
    "\n",
    "# Get 30 most common tokens amongst all tokenizaitons\n",
    "def get_total_common_tokens(tok_list):\n",
    "    all_tokens = []\n",
    "    for i in tok_list:\n",
    "        all_tokens= all_tokens + i\n",
    "    return list(dict.fromkeys([item for items, c in Counter(all_tokens).most_common() for item in [items] * c]))[:30]\n",
    "\n",
    "# Get percent of tokens appearing only once\n",
    "def get_unique_token_percentage(ind_list):\n",
    "    unique_instances = len([i for i in ind_list if ind_list.count(i)==1])\n",
    "    unique_instances_perc = round((unique_instances*100/len(set(ind_list))),2)\n",
    "    return unique_instances_perc\n",
    "\n",
    "def batch_unique_token_percentages(list_of_lists):\n",
    "    return [get_unique_token_percentage(i) for i in list_of_lists]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a00a6953",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "786212fb",
   "metadata": {},
   "source": [
    "<h3>Getting Correct Tokenizations</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fc36f0e",
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with 'Python 3.10.4 64-bit (windows store)' requires ipykernel package.\n",
      "Run the following command to install 'ipykernel' into the Python environment. \n",
      "Command: 'C:/Users/gimi1/AppData/Local/Microsoft/WindowsApps/python3.10.exe -m pip install ipykernel -U --user --force-reinstall'"
     ]
    }
   ],
   "source": [
    "# Get correct Tokenizations\n",
    "wjs_correct_tokenization = [item for sublist in [i for i in treebank.sents(treebank.fileids())] for item in sublist]\n",
    "vima_correct_tokenization = [i for i in (''.join([(open('assignment1textfiles/sbd/' + i, encoding=\"utf8\").read()) for i in os.listdir('assignment1textfiles/sbd')]).replace('<S>', '').split('\\n')) if i != '']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18f0b43a",
   "metadata": {},
   "source": [
    "<h3>Tokenization when dealing with English</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f9cddc6",
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with 'Python 3.10.4 64-bit (windows store)' requires ipykernel package.\n",
      "Run the following command to install 'ipykernel' into the Python environment. \n",
      "Command: 'C:/Users/gimi1/AppData/Local/Microsoft/WindowsApps/python3.10.exe -m pip install ipykernel -U --user --force-reinstall'"
     ]
    }
   ],
   "source": [
    "# Loading Wall Street Journal\n",
    "wsj_raw_text = open(\"assignment1textfiles/wsj_untokenized.txt\", \"r\").read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "204a7cf3",
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with 'Python 3.10.4 64-bit (windows store)' requires ipykernel package.\n",
      "Run the following command to install 'ipykernel' into the Python environment. \n",
      "Command: 'C:/Users/gimi1/AppData/Local/Microsoft/WindowsApps/python3.10.exe -m pip install ipykernel -U --user --force-reinstall'"
     ]
    }
   ],
   "source": [
    "# nltk word_tokenize\n",
    "wsj_nltk_word_tokenize = word_tokenize(wsj_raw_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5379bc7e",
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with 'Python 3.10.4 64-bit (windows store)' requires ipykernel package.\n",
      "Run the following command to install 'ipykernel' into the Python environment. \n",
      "Command: 'C:/Users/gimi1/AppData/Local/Microsoft/WindowsApps/python3.10.exe -m pip install ipykernel -U --user --force-reinstall'"
     ]
    }
   ],
   "source": [
    "# nltk wordpunct_tokenize\n",
    "wsj_nltk_tokenize_wordpunct_tokenize = wordpunct_tokenize(wsj_raw_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca913db7",
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with 'Python 3.10.4 64-bit (windows store)' requires ipykernel package.\n",
      "Run the following command to install 'ipykernel' into the Python environment. \n",
      "Command: 'C:/Users/gimi1/AppData/Local/Microsoft/WindowsApps/python3.10.exe -m pip install ipykernel -U --user --force-reinstall'"
     ]
    }
   ],
   "source": [
    "# spacy tokenization\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "spacy_en_tokens = [i.text for i in nlp(wsj_raw_text.strip())]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4c5145c",
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with 'Python 3.10.4 64-bit (windows store)' requires ipykernel package.\n",
      "Run the following command to install 'ipykernel' into the Python environment. \n",
      "Command: 'C:/Users/gimi1/AppData/Local/Microsoft/WindowsApps/python3.10.exe -m pip install ipykernel -U --user --force-reinstall'"
     ]
    }
   ],
   "source": [
    "# custom regex tokenization\n",
    "regex_en_tokens = re.findall(\"[-'()]|[^a-z0-9 ](?= )|(?:[a-z0-9]|[^-'()a-z0-9 ](?! ))+\", wsj_raw_text, re.IGNORECASE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4b2cf88",
   "metadata": {},
   "source": [
    "<h3>Tokenization when dealing with Greek</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f943016",
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with 'Python 3.10.4 64-bit (windows store)' requires ipykernel package.\n",
      "Run the following command to install 'ipykernel' into the Python environment. \n",
      "Command: 'C:/Users/gimi1/AppData/Local/Microsoft/WindowsApps/python3.10.exe -m pip install ipykernel -U --user --force-reinstall'"
     ]
    }
   ],
   "source": [
    "# Loading all texts from Vima\n",
    "import os\n",
    "vima = ''.join([(open('assignment1textfiles/raw/' + i, encoding=\"utf8\").read()) for i in os.listdir('assignment1textfiles/raw')]).replace('\\n', ' ')                                                                           "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e0a1eba",
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with 'Python 3.10.4 64-bit (windows store)' requires ipykernel package.\n",
      "Run the following command to install 'ipykernel' into the Python environment. \n",
      "Command: 'C:/Users/gimi1/AppData/Local/Microsoft/WindowsApps/python3.10.exe -m pip install ipykernel -U --user --force-reinstall'"
     ]
    }
   ],
   "source": [
    "# nltk word_tokenize\n",
    "vima_nltk_word_tokenize = word_tokenize(vima)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7361109",
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with 'Python 3.10.4 64-bit (windows store)' requires ipykernel package.\n",
      "Run the following command to install 'ipykernel' into the Python environment. \n",
      "Command: 'C:/Users/gimi1/AppData/Local/Microsoft/WindowsApps/python3.10.exe -m pip install ipykernel -U --user --force-reinstall'"
     ]
    }
   ],
   "source": [
    "# nltk wordpunct_tokenize\n",
    "vima_nltk_tokenize_wordpunct_tokenize = wordpunct_tokenize(vima)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee09dc6a",
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with 'Python 3.10.4 64-bit (windows store)' requires ipykernel package.\n",
      "Run the following command to install 'ipykernel' into the Python environment. \n",
      "Command: 'C:/Users/gimi1/AppData/Local/Microsoft/WindowsApps/python3.10.exe -m pip install ipykernel -U --user --force-reinstall'"
     ]
    }
   ],
   "source": [
    "# spacy tokenization\n",
    "nlpg = spacy.load(\"el_core_news_sm\")\n",
    "spacy_gr_tokens = [i.text for i in nlpg(vima)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cecfce2",
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with 'Python 3.10.4 64-bit (windows store)' requires ipykernel package.\n",
      "Run the following command to install 'ipykernel' into the Python environment. \n",
      "Command: 'C:/Users/gimi1/AppData/Local/Microsoft/WindowsApps/python3.10.exe -m pip install ipykernel -U --user --force-reinstall'"
     ]
    }
   ],
   "source": [
    "# custom regex tokenization\n",
    "regex_gr_tokens = re.findall(\"[-'()]|[^α-ω0-9 ](?= )|(?:[α-ωόάώήί0-9]|[^-'()α-ω0-9 ](?! ))+\", vima, re.IGNORECASE)\n",
    "print('\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4d73c9b",
   "metadata": {},
   "source": [
    "<h3>Tokenization Comparison</h3>\n",
    "<h4>Wall Street Journal Tokenization<h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fe44357",
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with 'Python 3.10.4 64-bit (windows store)' requires ipykernel package.\n",
      "Run the following command to install 'ipykernel' into the Python environment. \n",
      "Command: 'C:/Users/gimi1/AppData/Local/Microsoft/WindowsApps/python3.10.exe -m pip install ipykernel -U --user --force-reinstall'"
     ]
    }
   ],
   "source": [
    "wsj_tokenizations = [wjs_correct_tokenization, wsj_nltk_word_tokenize, wsj_nltk_tokenize_wordpunct_tokenize, spacy_en_tokens, regex_en_tokens]\n",
    "tokenizer_names = ['Ground Truth', 'Nltk word_tokenize', 'Nltk tokenize.wordpunct_tokenize', 'Spacy Tokenization', 'Custom Regex Tokenization']\n",
    "accuracy_perc = [get_tokenization_accuracy(wjs_correct_tokenization, i)[0] for i in wsj_tokenizations]\n",
    "tokenization_lengths = get_tokenization_lens(wsj_tokenizations)\n",
    "# This takes a little while\n",
    "wsj_unique_token_perc = batch_unique_token_percentages(wsj_tokenizations)\n",
    "type_lengths =  get_type_lens(wsj_tokenizations)\n",
    "\n",
    "wsj_results = {'Tokenization Accuracy' : [], \"Token List Length\" : [], \"Type List Length\":[], \"Unique Token Percentage\":[]}\n",
    "for i in range(len(wsj_tokenizations)):\n",
    "    wsj_results['Tokenization Accuracy'].append(str(accuracy_perc[i]) + '%')\n",
    "    wsj_results[\"Token List Length\"].append(tokenization_lengths[i])\n",
    "    wsj_results[\"Type List Length\"].append(type_lengths[i])\n",
    "    wsj_results[\"Unique Token Percentage\"].append(wsj_unique_token_perc[i])\n",
    "print('Wall Street Journal Tokenization Results:\\n')\n",
    "pd.DataFrame(wsj_results, index = tokenizer_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3901048e",
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with 'Python 3.10.4 64-bit (windows store)' requires ipykernel package.\n",
      "Run the following command to install 'ipykernel' into the Python environment. \n",
      "Command: 'C:/Users/gimi1/AppData/Local/Microsoft/WindowsApps/python3.10.exe -m pip install ipykernel -U --user --force-reinstall'"
     ]
    }
   ],
   "source": [
    "# Getting the 30 most common tokens per tokenization\n",
    "for i in range(5):\n",
    "    print(tokenizer_names[i] + ' 30 most common tokens in order are:\\n')\n",
    "    print(get_ind_common_tokens(wsj_tokenizations[i]))\n",
    "    print('\\n')\n",
    "    \n",
    "# Getting 30 most common tokens overall\n",
    "print('The 30 most common tokens amongst all tokenizetions are:\\n')\n",
    "print(get_total_common_tokens([i for i in wsj_tokenizations]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49b889e5",
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with 'Python 3.10.4 64-bit (windows store)' requires ipykernel package.\n",
      "Run the following command to install 'ipykernel' into the Python environment. \n",
      "Command: 'C:/Users/gimi1/AppData/Local/Microsoft/WindowsApps/python3.10.exe -m pip install ipykernel -U --user --force-reinstall'"
     ]
    }
   ],
   "source": [
    "# To examine which tokens don't appear in a tokenization\n",
    "wsj_nltk_word_tokenize_missing, wsj_nltk_tokenize_wordpunct_tokenize_missing, spacy_en_tokens_missing, regex_en_tokens_missing = [get_tokenization_accuracy(wjs_correct_tokenization, i)[1] for i in wsj_tokenizations[1:]]\n",
    "\n",
    "# For example, here are 10 tokens that word_tokenize() fails to identify\n",
    "print('10 tokens that word_tokenize() fails to identify: \\n')\n",
    "print(wsj_nltk_word_tokenize_missing[:10])\n",
    "print('\\nA common theme is that both nltk and spacy tokenizers struggle when handling spacial charachters such as \"*\" and \"-\".')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "267ab4c3",
   "metadata": {},
   "source": [
    "<h4>Vima Tokenization<h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb724b78",
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with 'Python 3.10.4 64-bit (windows store)' requires ipykernel package.\n",
      "Run the following command to install 'ipykernel' into the Python environment. \n",
      "Command: 'C:/Users/gimi1/AppData/Local/Microsoft/WindowsApps/python3.10.exe -m pip install ipykernel -U --user --force-reinstall'"
     ]
    }
   ],
   "source": [
    "vima_tokenizations = [vima_correct_tokenization, vima_nltk_word_tokenize, vima_nltk_tokenize_wordpunct_tokenize, spacy_gr_tokens, regex_gr_tokens]\n",
    "tokenizer_names = ['Ground Truth', 'Nltk word_tokenize', 'Nltk tokenize.wordpunct_tokenize', 'Spacy Tokenization', 'Custom Regex Tokenization']\n",
    "accuracy_perc = [get_tokenization_accuracy(vima_correct_tokenization, i)[0] for i in vima_tokenizations]\n",
    "tokenization_lengths = get_tokenization_lens(wsj_tokenizations)\n",
    "# This takes a little while\n",
    "unique_token_perc = batch_unique_token_percentages(vima_tokenizations)\n",
    "type_lengths =  get_type_lens(vima_tokenizations)\n",
    "\n",
    "vima_results = {'Tokenization Accuracy' : [], \"Token List Length\" : [], \"Type List Length\":[], \"Unique Token Percentage\":[]}\n",
    "for i in range(len(vima_tokenizations)):\n",
    "    vima_results['Tokenization Accuracy'].append(str(accuracy_perc[i]) + '%')\n",
    "    vima_results[\"Token List Length\"].append(tokenization_lengths[i])\n",
    "    vima_results[\"Type List Length\"].append(type_lengths[i])\n",
    "    vima_results[\"Unique Token Percentage\"].append(unique_token_perc[i])\n",
    "print('Vima Tokenization Results:\\n')\n",
    "pd.DataFrame(vima_results, index = tokenizer_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83a7424e",
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with 'Python 3.10.4 64-bit (windows store)' requires ipykernel package.\n",
      "Run the following command to install 'ipykernel' into the Python environment. \n",
      "Command: 'C:/Users/gimi1/AppData/Local/Microsoft/WindowsApps/python3.10.exe -m pip install ipykernel -U --user --force-reinstall'"
     ]
    }
   ],
   "source": [
    "# Getting the 30 most common tokens per tokenization\n",
    "for i in range(5):\n",
    "    print(tokenizer_names[i] + ' 30 most common tokens in order are:\\n')\n",
    "    print(get_ind_common_tokens(vima_tokenizations[i]))\n",
    "    print('\\n')\n",
    "    \n",
    "# Getting 30 most common tokens overall\n",
    "print('The 30 most common tokens amongst all tokenizetions are:\\n')\n",
    "print(get_total_common_tokens([i for i in vima_tokenizations]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "765166d0",
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with 'Python 3.10.4 64-bit (windows store)' requires ipykernel package.\n",
      "Run the following command to install 'ipykernel' into the Python environment. \n",
      "Command: 'C:/Users/gimi1/AppData/Local/Microsoft/WindowsApps/python3.10.exe -m pip install ipykernel -U --user --force-reinstall'"
     ]
    }
   ],
   "source": [
    "# Tokens that don't appear in a tokenization\n",
    "vima_nltk_word_tokenize_missing, vima_nltk_tokenize_wordpunct_tokenize_missing, spacy_gr_tokens_missing, regex_gr_tokens_missing = [get_tokenization_accuracy(vima_correct_tokenization, i)[1] for i in vima_tokenizations[1:]]\n",
    "\n",
    "# For example, here are 10 tokens that word_tokenize() fails to identify\n",
    "print('10 tokens that the regex tokenizer fails to identify: \\n')\n",
    "print(regex_gr_tokens_missing[:10])\n",
    "print('\\nAgain, the common theme is a difficulty when dealing with special characters and symbols')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37d660db",
   "metadata": {},
   "source": [
    "<br><br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd1dcab6",
   "metadata": {},
   "source": [
    "<h2>Sentence Boundary Disambiguation</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f17b74b",
   "metadata": {},
   "source": [
    "<h3>Function to extract Sentence Boundary Disambiguation metrics</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63572fcf",
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with 'Python 3.10.4 64-bit (windows store)' requires ipykernel package.\n",
      "Run the following command to install 'ipykernel' into the Python environment. \n",
      "Command: 'C:/Users/gimi1/AppData/Local/Microsoft/WindowsApps/python3.10.exe -m pip install ipykernel -U --user --force-reinstall'"
     ]
    }
   ],
   "source": [
    "# Helper for wsj ground trouth\n",
    "def remove_if_contains(the_list, character):\n",
    "    for i in range(len(the_list)):\n",
    "        list_words = the_list[i].split()\n",
    "\n",
    "        for j in reversed(range(len(list_words))):\n",
    "\n",
    "            if character in str(list_words[j]):\n",
    "                list_words.pop(j) \n",
    "        the_list[i] = ' '.join(list_words)\n",
    "    return the_list\n",
    "# Get Metrics of a list\n",
    "def get_presition(gt, other_sbd):\n",
    "    unified_set = set(list(itertools.chain(gt, other_sbd)))\n",
    "    ot_set = set(other_sbd)\n",
    "    cor_set = set(gt)\n",
    "    tp = ot_set.intersection(cor_set)\n",
    "    fp = ot_set.difference(cor_set)\n",
    "    fn = cor_set.difference(ot_set)\n",
    "    precision = round((len(tp)/ (len(tp)+len(fp))),3)\n",
    "\n",
    "    return precision\n",
    "\n",
    "def get_recall(gt, other_sbd):\n",
    "    unified_set = set(list(itertools.chain(gt, other_sbd)))\n",
    "    ot_set = set(other_sbd)\n",
    "    cor_set = set(gt)\n",
    "    tp = ot_set.intersection(cor_set)\n",
    "    fp = ot_set.difference(cor_set)\n",
    "    fn = cor_set.difference(ot_set)\n",
    "    recall = round((len(tp)/ (len(tp)+len(fn))),3)\n",
    "    return recall\n",
    "\n",
    "def get_f1(gt, other_sbd):\n",
    "    f1_score = 2*(get_presition(gt, other_sbd)*get_recall(gt, other_sbd)/(get_presition(gt, other_sbd)+get_recall(gt, other_sbd)))\n",
    "    return f1_score\n",
    "\n",
    "\n",
    "# Get average length of strings of a list\n",
    "def get_avg_len(sbd_list):\n",
    "    return round(sum(map(len, sbd_list))/float(len(sbd_list)),2)\n",
    "\n",
    "# Get min length of strings in lists\n",
    "def get_min_len(sbd_list):\n",
    "    return len(min(sbd_list, key=len))\n",
    "\n",
    "# Get max length of strings in list\n",
    "def get_max_len(sbd_list):\n",
    "    return len(max(sbd_list, key=len))\n",
    "\n",
    "# Get average number of tokens per sentence\n",
    "def avg_tokens(sbd_list):\n",
    "    token_len = [len(i) for i in [word_tokenize(i) for i in sbd_list]]\n",
    "    return round(sum(token_len)/len(token_len),2)\n",
    "\n",
    "# Get max number of tokens of sbd\n",
    "def max_tokens(sbd_list):\n",
    "    return max([len(i) for i in [word_tokenize(i) for i in sbd_list]])\n",
    "\n",
    "# Get min number of tokens of sbd\n",
    "def min_tokens(sbd_list):\n",
    "    return min([len(i) for i in [word_tokenize(i) for i in sbd_list]])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c496287e",
   "metadata": {},
   "source": [
    "<h3>Getting Correct Sentence Boundaries</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecbb7bf0",
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with 'Python 3.10.4 64-bit (windows store)' requires ipykernel package.\n",
      "Run the following command to install 'ipykernel' into the Python environment. \n",
      "Command: 'C:/Users/gimi1/AppData/Local/Microsoft/WindowsApps/python3.10.exe -m pip install ipykernel -U --user --force-reinstall'"
     ]
    }
   ],
   "source": [
    "# Get correct Sentence Boundaries\n",
    "vima_correct_sbd = re.sub('\\s*([.;,])', r'\\1', ''.join([(open('assignment1textfiles/sbd/' + i, encoding=\"utf8\").read().strip()) for i in os.listdir('assignment1textfiles/sbd')]).replace('\\n',' ')).split('<S>')\n",
    "for i in range(len(vima_correct_sbd)):\n",
    "    vima_correct_sbd[i] = vima_correct_sbd[i].strip()\n",
    "# wsj_correct_sbd = [re.sub('\\s*([.;,])',r'\\1', ' '.join(i)) for i in [item for sublist in [treebank.sents(treebank.fileids())] for item in sublist]]\n",
    "\n",
    "wsj_correct_sbd = [re.sub('\\s*([.;,])',r'\\1', ' '.join(i)) for i in treebank.sents()]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1dd7b6a0",
   "metadata": {},
   "source": [
    "<h3>Sentence Boundary Disambiguation when dealing with English</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "656225fa",
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with 'Python 3.10.4 64-bit (windows store)' requires ipykernel package.\n",
      "Run the following command to install 'ipykernel' into the Python environment. \n",
      "Command: 'C:/Users/gimi1/AppData/Local/Microsoft/WindowsApps/python3.10.exe -m pip install ipykernel -U --user --force-reinstall'"
     ]
    }
   ],
   "source": [
    "# Additional imports\n",
    "from nltk import sent_tokenize\n",
    "from nltk.tokenize import PunktSentenceTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "962792d1",
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with 'Python 3.10.4 64-bit (windows store)' requires ipykernel package.\n",
      "Run the following command to install 'ipykernel' into the Python environment. \n",
      "Command: 'C:/Users/gimi1/AppData/Local/Microsoft/WindowsApps/python3.10.exe -m pip install ipykernel -U --user --force-reinstall'"
     ]
    }
   ],
   "source": [
    "# nltk sent_tokenize\n",
    "wsj_nltk_sent_tokenize = sent_tokenize(wsj_raw_text.strip())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "266b48fc",
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with 'Python 3.10.4 64-bit (windows store)' requires ipykernel package.\n",
      "Run the following command to install 'ipykernel' into the Python environment. \n",
      "Command: 'C:/Users/gimi1/AppData/Local/Microsoft/WindowsApps/python3.10.exe -m pip install ipykernel -U --user --force-reinstall'"
     ]
    }
   ],
   "source": [
    "# nltk PunktSentenceTokenizer\n",
    "wsj_nltk_punkt_sent_tokenize = PunktSentenceTokenizer(wsj_raw_text.strip()).sentences_from_text(wsj_raw_text.strip())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "007b6c70",
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with 'Python 3.10.4 64-bit (windows store)' requires ipykernel package.\n",
      "Run the following command to install 'ipykernel' into the Python environment. \n",
      "Command: 'C:/Users/gimi1/AppData/Local/Microsoft/WindowsApps/python3.10.exe -m pip install ipykernel -U --user --force-reinstall'"
     ]
    }
   ],
   "source": [
    "# spacy sentence boundary disambiguation\n",
    "spacy_en_sbd = [str(i.sent).strip() for i in nlp(wsj_raw_text)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7083b85",
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with 'Python 3.10.4 64-bit (windows store)' requires ipykernel package.\n",
      "Run the following command to install 'ipykernel' into the Python environment. \n",
      "Command: 'C:/Users/gimi1/AppData/Local/Microsoft/WindowsApps/python3.10.exe -m pip install ipykernel -U --user --force-reinstall'"
     ]
    }
   ],
   "source": [
    "# custom regex sentence boundary disambiguation\n",
    "sbd_en_regex = re.findall(r\"[A-Z].*?[\\.!?] \", wsj_raw_text) # A space is included at the end so that numbers with decimals won't trigger a new sentence\n",
    "for i in range(len(sbd_en_regex)):\n",
    "    sbd_en_regex[i] = sbd_en_regex[i][:-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5791e76c",
   "metadata": {},
   "source": [
    "<h3>Sentence Boundary Disambiguation when dealing with Greek</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bbc7a31",
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with 'Python 3.10.4 64-bit (windows store)' requires ipykernel package.\n",
      "Run the following command to install 'ipykernel' into the Python environment. \n",
      "Command: 'C:/Users/gimi1/AppData/Local/Microsoft/WindowsApps/python3.10.exe -m pip install ipykernel -U --user --force-reinstall'"
     ]
    }
   ],
   "source": [
    "# nltk sent_tokenize\n",
    "vima_nltk_sent_tokenize = sent_tokenize(vima)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54403cf9",
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with 'Python 3.10.4 64-bit (windows store)' requires ipykernel package.\n",
      "Run the following command to install 'ipykernel' into the Python environment. \n",
      "Command: 'C:/Users/gimi1/AppData/Local/Microsoft/WindowsApps/python3.10.exe -m pip install ipykernel -U --user --force-reinstall'"
     ]
    }
   ],
   "source": [
    "# nltk PunktSentenceTokenizer\n",
    "vima_nltk_punkt_sent_tokenize = PunktSentenceTokenizer(vima).sentences_from_text(vima)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08702a24",
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with 'Python 3.10.4 64-bit (windows store)' requires ipykernel package.\n",
      "Run the following command to install 'ipykernel' into the Python environment. \n",
      "Command: 'C:/Users/gimi1/AppData/Local/Microsoft/WindowsApps/python3.10.exe -m pip install ipykernel -U --user --force-reinstall'"
     ]
    }
   ],
   "source": [
    "# spacy sentence boundary disambiguation\n",
    "spacy_gr_sbd = [str(i.sent) for i in nlp(vima).sents]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5bdc298",
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with 'Python 3.10.4 64-bit (windows store)' requires ipykernel package.\n",
      "Run the following command to install 'ipykernel' into the Python environment. \n",
      "Command: 'C:/Users/gimi1/AppData/Local/Microsoft/WindowsApps/python3.10.exe -m pip install ipykernel -U --user --force-reinstall'"
     ]
    }
   ],
   "source": [
    "# custom regex sentence boundary disambiguation\n",
    "sbd_gr_regex = re.findall(r\"[Α-Ω].*?[\\.!?]\", vima)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed048c78",
   "metadata": {},
   "source": [
    "<h3>Sentence Boundary Disambiguation Comparison</h3>\n",
    "<h4>Wall Street Journal SBD<h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "472a91b5",
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with 'Python 3.10.4 64-bit (windows store)' requires ipykernel package.\n",
      "Run the following command to install 'ipykernel' into the Python environment. \n",
      "Command: 'C:/Users/gimi1/AppData/Local/Microsoft/WindowsApps/python3.10.exe -m pip install ipykernel -U --user --force-reinstall'"
     ]
    }
   ],
   "source": [
    "wsj_sbds = [wsj_correct_sbd, wsj_nltk_sent_tokenize, wsj_nltk_punkt_sent_tokenize, spacy_en_sbd, sbd_en_regex]\n",
    "tokenizer_names = ['Ground Truth', 'Nltk sent_tokenize', 'Nltk PunktSentenceTokenizer', 'Spacy SBD', 'Custom Regex SBD']\n",
    "presc = [get_presition(wsj_correct_sbd, i) for i in wsj_sbds]\n",
    "recall = [get_recall(wsj_correct_sbd, i) for i in wsj_sbds]\n",
    "f1 = [get_f1(wsj_correct_sbd, i) for i in wsj_sbds]\n",
    "min_len = [get_min_len(i) for i in wsj_sbds]\n",
    "max_len = [get_max_len(i) for i in wsj_sbds]\n",
    "avg_len = [get_avg_len(i) for i in wsj_sbds]\n",
    "min_tok = [min_tokens(i) for i in wsj_sbds]\n",
    "max_tok = [max_tokens(i) for i in wsj_sbds]\n",
    "avg_tok = [avg_tokens(i) for i in wsj_sbds]\n",
    "\n",
    "wsj_results = {'Precision' : [], \"Recall\":[], \"F1 Score\":[], 'Min Length':[], 'Max Length' : [], 'Average Length' : [], 'Min Tokens':[], 'Max Tokens':[],'Average Tokens':[],}\n",
    "for i in range(len(wsj_sbds)):\n",
    "    wsj_results['Precision'].append(presc[i])\n",
    "    wsj_results[\"Recall\"].append(recall[i])\n",
    "    wsj_results[\"F1 Score\"].append(f1[i])\n",
    "    wsj_results[\"Min Length\"].append(min_len[i])\n",
    "    wsj_results[\"Max Length\"].append(max_len[i])\n",
    "    wsj_results[\"Average Length\"].append(avg_len[i])\n",
    "    wsj_results[\"Min Tokens\"].append(min_tok[i])\n",
    "    wsj_results[\"Max Tokens\"].append(max_tok[i])\n",
    "    wsj_results[\"Average Tokens\"].append(avg_tok[i])\n",
    "\n",
    "print('Wall Street Journal SBD Results:\\n')\n",
    "pd.DataFrame(wsj_results, index = tokenizer_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85317cd4",
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with 'Python 3.10.4 64-bit (windows store)' requires ipykernel package.\n",
      "Run the following command to install 'ipykernel' into the Python environment. \n",
      "Command: 'C:/Users/gimi1/AppData/Local/Microsoft/WindowsApps/python3.10.exe -m pip install ipykernel -U --user --force-reinstall'"
     ]
    }
   ],
   "source": [
    "vima_sbds = [vima_correct_sbd, vima_nltk_sent_tokenize, vima_nltk_punkt_sent_tokenize, spacy_gr_sbd, sbd_gr_regex]\n",
    "tokenizer_names = ['Ground Truth', 'Nltk sent_tokenize', 'Nltk PunktSentenceTokenizer', 'Spacy SBD', 'Custom Regex SBD']\n",
    "presc = [get_presition(vima_correct_sbd, i) for i in vima_sbds]\n",
    "recall = [get_recall(vima_correct_sbd, i) for i in vima_sbds]\n",
    "f1 = [get_f1(vima_correct_sbd, i) for i in vima_sbds]\n",
    "min_len = [get_min_len(i) for i in vima_sbds]\n",
    "max_len = [get_max_len(i) for i in vima_sbds]\n",
    "avg_len = [get_avg_len(i) for i in vima_sbds]\n",
    "min_tok = [min_tokens(i) for i in vima_sbds]\n",
    "max_tok = [max_tokens(i) for i in vima_sbds]\n",
    "avg_tok = [avg_tokens(i) for i in vima_sbds]\n",
    "\n",
    "vima_results = {'Precision' : [], \"Recall\":[], \"F1 Score\":[], 'Min Length':[], 'Max Length' : [], 'Average Length' : [], 'Min Tokens':[], 'Max Tokens':[],'Average Tokens':[],}\n",
    "for i in range(len(wsj_sbds)):\n",
    "    vima_results['Precision'].append(presc[i])\n",
    "    vima_results[\"Recall\"].append(recall[i])\n",
    "    vima_results[\"F1 Score\"].append(f1[i])\n",
    "    vima_results[\"Min Length\"].append(min_len[i])\n",
    "    vima_results[\"Max Length\"].append(max_len[i])\n",
    "    vima_results[\"Average Length\"].append(avg_len[i])\n",
    "    vima_results[\"Min Tokens\"].append(min_tok[i])\n",
    "    vima_results[\"Max Tokens\"].append(max_tok[i])\n",
    "    vima_results[\"Average Tokens\"].append(avg_tok[i])\n",
    "\n",
    "print('Vima SBD Results:\\n')\n",
    "pd.DataFrame(vima_results, index = tokenizer_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "078880f9",
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with 'Python 3.10.4 64-bit (windows store)' requires ipykernel package.\n",
      "Run the following command to install 'ipykernel' into the Python environment. \n",
      "Command: 'C:/Users/gimi1/AppData/Local/Microsoft/WindowsApps/python3.10.exe -m pip install ipykernel -U --user --force-reinstall'"
     ]
    }
   ],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
